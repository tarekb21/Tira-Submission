{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline for Native Advertisement Detection Using TF-IDF and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Loading: Merges responses and labels from JSONL files.\n",
    "2. Feature Extraction: Transforms text into TF-IDF features (with stop-word removal and max_df filtering).\n",
    "3. Classification: Uses Logistic Regression (max_iter=1000, random_state=42) for binary classification.\n",
    "4. Evaluation: Applies 5-fold cross-validation and evaluates on training, validation, and test sets.\n",
    "5. Submission: Generates predictions in JSONL format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation F1 Macro Scores on Training Set: [0.67887449 0.6722082  0.69065799 0.66471172 0.67489588]\n",
      "Mean Cross-Validation F1 Macro Score: 0.6762696572899445\n",
      "\n",
      "Training Set Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89      7541\n",
      "           1       0.94      0.57      0.71      3946\n",
      "\n",
      "    accuracy                           0.84     11487\n",
      "   macro avg       0.88      0.78      0.80     11487\n",
      "weighted avg       0.86      0.84      0.83     11487\n",
      "\n",
      "Confusion Matrix (Training):\n",
      "[[7408  133]\n",
      " [1688 2258]]\n",
      "\n",
      "Validation Set Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.97      0.83      2075\n",
      "           1       0.87      0.37      0.52      1182\n",
      "\n",
      "    accuracy                           0.75      3257\n",
      "   macro avg       0.80      0.67      0.68      3257\n",
      "weighted avg       0.78      0.75      0.72      3257\n",
      "\n",
      "Confusion Matrix (Validation):\n",
      "[[2008   67]\n",
      " [ 743  439]]\n",
      "\n",
      "Test Set Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.97      0.85      1687\n",
      "           1       0.89      0.40      0.55       913\n",
      "\n",
      "    accuracy                           0.77      2600\n",
      "   macro avg       0.82      0.69      0.70      2600\n",
      "weighted avg       0.80      0.77      0.74      2600\n",
      "\n",
      "Confusion Matrix (Test):\n",
      "[[1643   44]\n",
      " [ 547  366]]\n",
      "\n",
      "Submission file saved to: /Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/baseline.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "def load_dataset(responses_file, labels_file):\n",
    "    \"\"\"\n",
    "    Load dataset by reading responses and labels from JSONL files and merging them.\n",
    "    \"\"\"\n",
    "    # Load responses into a dictionary mapping id -> response text\n",
    "    responses = {}\n",
    "    with open(responses_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            # Here you can combine 'query' and 'response' if needed.\n",
    "            responses[data[\"id\"]] = data[\"response\"]\n",
    "    \n",
    "    # Load labels and merge with responses\n",
    "    ids, texts, labels = [], [], []\n",
    "    with open(labels_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            instance_id = data[\"id\"]\n",
    "            if instance_id in responses:\n",
    "                ids.append(instance_id)\n",
    "                texts.append(responses[instance_id])\n",
    "                labels.append(data[\"label\"])\n",
    "    \n",
    "    return ids, texts, labels\n",
    "\n",
    "# File paths (update these paths as needed)\n",
    "train_responses_file = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-train.jsonl'\n",
    "train_labels_file = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-train-labels.jsonl'\n",
    "val_responses_file   = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-validation.jsonl'\n",
    "val_labels_file      = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-validation-labels.jsonl'\n",
    "test_responses_file  = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-test.jsonl'\n",
    "test_labels_file     = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-test-labels.jsonl'\n",
    "\n",
    "# Load datasets\n",
    "train_ids, train_texts, train_labels = load_dataset(train_responses_file, train_labels_file)\n",
    "val_ids, val_texts, val_labels = load_dataset(val_responses_file, val_labels_file)\n",
    "test_ids, test_texts, test_labels = load_dataset(test_responses_file, test_labels_file)\n",
    "\n",
    "# Build the pipeline: TF-IDF vectorizer + Logistic Regression\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(stop_words='english', max_df=0.95),\n",
    "    LogisticRegression(max_iter=1000, random_state=42)\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Cross-Validation on Training Set\n",
    "# -------------------------\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(pipeline, train_texts, train_labels, cv=cv, scoring='f1_macro')\n",
    "print(\"Cross-validation F1 Macro Scores on Training Set:\", cv_scores)\n",
    "print(\"Mean Cross-Validation F1 Macro Score:\", np.mean(cv_scores))\n",
    "\n",
    "# -------------------------\n",
    "# Train the Model on the Full Training Set\n",
    "# -------------------------\n",
    "pipeline.fit(train_texts, train_labels)\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation on Training Set\n",
    "# -------------------------\n",
    "train_preds = pipeline.predict(train_texts)\n",
    "print(\"\\nTraining Set Evaluation:\")\n",
    "print(classification_report(train_labels, train_preds))\n",
    "print(\"Confusion Matrix (Training):\")\n",
    "print(confusion_matrix(train_labels, train_preds))\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation on Validation Set\n",
    "# -------------------------\n",
    "val_preds = pipeline.predict(val_texts)\n",
    "print(\"\\nValidation Set Evaluation:\")\n",
    "print(classification_report(val_labels, val_preds))\n",
    "print(\"Confusion Matrix (Validation):\")\n",
    "print(confusion_matrix(val_labels, val_preds))\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation on Test Set\n",
    "# -------------------------\n",
    "test_preds = pipeline.predict(test_texts)\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(classification_report(test_labels, test_preds))\n",
    "print(\"Confusion Matrix (Test):\")\n",
    "print(confusion_matrix(test_labels, test_preds))\n",
    "\n",
    "# -------------------------\n",
    "# Submission File Generation\n",
    "# -------------------------\n",
    "submission_file = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/baseline.jsonl'\n",
    "with open(submission_file, 'w', encoding='utf-8') as f_out:\n",
    "    for instance_id, pred in zip(test_ids, test_preds):\n",
    "        result = {\n",
    "            \"id\": instance_id,\n",
    "            \"label\": int(pred),  # ensuring it's an integer (0 or 1)\n",
    "            \"tag\": \"myGroupMyMethod\"\n",
    "        }\n",
    "        f_out.write(json.dumps(result) + \"\\n\")\n",
    "        \n",
    "print(f\"\\nSubmission file saved to: {submission_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed Version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation F1 Score (for ad detection, label=1) on Combined Training Set: [0.57534247 0.57050453 0.56031128 0.57591623 0.57217505]\n",
      "Mean Cross-Validation F1 Score: 0.5708499113935824\n",
      "\n",
      "Combined Training Set Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.98      0.90      9616\n",
      "           1       0.94      0.62      0.75      5128\n",
      "\n",
      "    accuracy                           0.85     14744\n",
      "   macro avg       0.89      0.80      0.82     14744\n",
      "weighted avg       0.87      0.85      0.85     14744\n",
      "\n",
      "Confusion Matrix (Combined Training):\n",
      "[[9424  192]\n",
      " [1948 3180]]\n",
      "F1 Score for ads (label 1): 0.7482352941176471\n",
      "\n",
      "Test Set Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.97      0.86      1687\n",
      "           1       0.89      0.45      0.60       913\n",
      "\n",
      "    accuracy                           0.79      2600\n",
      "   macro avg       0.83      0.71      0.73      2600\n",
      "weighted avg       0.81      0.79      0.77      2600\n",
      "\n",
      "Confusion Matrix (Test):\n",
      "[[1638   49]\n",
      " [ 503  410]]\n",
      "F1 Score for ads (label 1): 0.597667638483965\n",
      "\n",
      "Submission file saved to: /Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/baseline2.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "def load_dataset(responses_file, labels_file):\n",
    "    \"\"\"\n",
    "    Load dataset by reading responses and labels from JSONL files and merging them.\n",
    "    \"\"\"\n",
    "    # Load responses into a dictionary mapping id -> response text\n",
    "    responses = {}\n",
    "    with open(responses_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            responses[data[\"id\"]] = data[\"response\"]\n",
    "    \n",
    "    # Load labels and merge with responses\n",
    "    ids, texts, labels = [], [], []\n",
    "    with open(labels_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            instance_id = data[\"id\"]\n",
    "            if instance_id in responses:\n",
    "                ids.append(instance_id)\n",
    "                texts.append(responses[instance_id])\n",
    "                labels.append(data[\"label\"])\n",
    "    \n",
    "    return ids, texts, labels\n",
    "\n",
    "# File paths (update these paths as needed)\n",
    "train_responses_file = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-train.jsonl'\n",
    "train_labels_file = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-train-labels.jsonl'\n",
    "val_responses_file   = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-validation.jsonl'\n",
    "val_labels_file      = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-validation-labels.jsonl'\n",
    "test_responses_file  = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-test.jsonl'\n",
    "test_labels_file     = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-test-labels.jsonl'\n",
    "\n",
    "# Load train and validation datasets separately\n",
    "train_ids, train_texts, train_labels = load_dataset(train_responses_file, train_labels_file)\n",
    "val_ids, val_texts, val_labels = load_dataset(val_responses_file, val_labels_file)\n",
    "\n",
    "# Combine train and validation sets into one training set\n",
    "combined_ids = train_ids + val_ids\n",
    "combined_texts = train_texts + val_texts\n",
    "combined_labels = train_labels + val_labels\n",
    "\n",
    "# Load test dataset\n",
    "test_ids, test_texts, test_labels = load_dataset(test_responses_file, test_labels_file)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Experiment: Logistic Regression with TF-IDF for Advertisement Detection\n",
    "# Classifier: Logistic Regression (predicts label 1 as advertisement)\n",
    "# Feature Extraction: TF-IDF\n",
    "# Goal: Evaluate performance specifically for detecting advertisements (label 1)\n",
    "# -----------------------------------------------------\n",
    "\n",
    "# Build the pipeline: TF-IDF vectorizer + Logistic Regression\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(stop_words='english', max_df=0.95),\n",
    "    LogisticRegression(max_iter=1000, random_state=42)\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Cross-Validation on Combined Training Set\n",
    "# -------------------------\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# Use scoring 'f1' which for binary classification computes F1 score for the positive class (label 1)\n",
    "cv_scores = cross_val_score(pipeline, combined_texts, combined_labels, cv=cv, scoring='f1')\n",
    "print(\"Cross-validation F1 Score (for ad detection, label=1) on Combined Training Set:\", cv_scores)\n",
    "print(\"Mean Cross-Validation F1 Score:\", np.mean(cv_scores))\n",
    "\n",
    "# -------------------------\n",
    "# Train the Model on the Full Combined Training Set\n",
    "# -------------------------\n",
    "pipeline.fit(combined_texts, combined_labels)\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation on Combined Training Set\n",
    "# -------------------------\n",
    "train_preds = pipeline.predict(combined_texts)\n",
    "print(\"\\nCombined Training Set Evaluation:\")\n",
    "print(classification_report(combined_labels, train_preds))\n",
    "print(\"Confusion Matrix (Combined Training):\")\n",
    "print(confusion_matrix(combined_labels, train_preds))\n",
    "# Calculate F1 Score for label 1 explicitly:\n",
    "print(\"F1 Score for ads (label 1):\", f1_score(combined_labels, train_preds, pos_label=1))\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation on Test Set\n",
    "# -------------------------\n",
    "test_preds = pipeline.predict(test_texts)\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(classification_report(test_labels, test_preds))\n",
    "print(\"Confusion Matrix (Test):\")\n",
    "print(confusion_matrix(test_labels, test_preds))\n",
    "print(\"F1 Score for ads (label 1):\", f1_score(test_labels, test_preds, pos_label=1))\n",
    "\n",
    "# -------------------------\n",
    "# Submission File Generation\n",
    "# -------------------------\n",
    "submission_file = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/baseline2.jsonl'\n",
    "with open(submission_file, 'w', encoding='utf-8') as f_out:\n",
    "    for instance_id, pred in zip(test_ids, test_preds):\n",
    "        result = {\n",
    "            \"id\": instance_id,\n",
    "            \"label\": int(pred),  # ensuring it's an integer (0 or 1)\n",
    "            \"tag\": \"myGroupMyMethod\"\n",
    "        }\n",
    "        f_out.write(json.dumps(result) + \"\\n\")\n",
    "        \n",
    "print(f\"\\nSubmission file saved to: {submission_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation F1 Score (for ad detection, label=1) on Combined Training Set: [0.71892925 0.72276265 0.71688823 0.73277968 0.73611794]\n",
      "Mean Cross-validation F1 Score: 0.7254955492618423\n",
      "\n",
      "Combined Training Set Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      9616\n",
      "           1       0.85      0.89      0.87      5128\n",
      "\n",
      "    accuracy                           0.91     14744\n",
      "   macro avg       0.89      0.90      0.90     14744\n",
      "weighted avg       0.91      0.91      0.91     14744\n",
      "\n",
      "Confusion Matrix (Combined Training):\n",
      "[[8801  815]\n",
      " [ 551 4577]]\n",
      "F1 Score for ads (label 1): 0.8701520912547529\n",
      "\n",
      "Test Set Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      1687\n",
      "           1       0.80      0.71      0.76       913\n",
      "\n",
      "    accuracy                           0.84      2600\n",
      "   macro avg       0.83      0.81      0.82      2600\n",
      "weighted avg       0.84      0.84      0.84      2600\n",
      "\n",
      "Confusion Matrix (Test):\n",
      "[[1529  158]\n",
      " [ 263  650]]\n",
      "F1 Score for ads (label 1): 0.7553747821034282\n",
      "Detection Accuracy for ads (label 1): 0.7119386637458927\n",
      "False Negative Rate for ads (label 1): 0.28806133625410735\n",
      "False Positive Rate for ads (label 1): 0.0936573799644339\n",
      "F1-score for detecting ads: 0.7553747821034282\n",
      "Detection Accuracy for non-ads (label 0): 0.9063426200355661\n",
      "False Negative Rate for non-ads (label 0): 0.0936573799644339\n",
      "False Positive Rate for non-ads (label 0): 0.28806133625410735\n",
      "F1-score for non-detecting ads: 0.8789882150043116\n",
      "\n",
      "Submission file saved to: /Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/Advertisment-Detection/Submission/baseline2.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "def load_dataset(responses_file, labels_file):\n",
    "    \"\"\"\n",
    "    Load dataset by reading responses and labels from JSONL files and merging them.\n",
    "    \"\"\"\n",
    "    # Load responses into a dictionary mapping id -> response text\n",
    "    responses = {}\n",
    "    with open(responses_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            responses[data[\"id\"]] = data[\"response\"]\n",
    "    \n",
    "    # Load labels and merge with responses\n",
    "    ids, texts, labels = [], [], []\n",
    "    with open(labels_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            instance_id = data[\"id\"]\n",
    "            if instance_id in responses:\n",
    "                ids.append(instance_id)\n",
    "                texts.append(responses[instance_id])\n",
    "                labels.append(data[\"label\"])\n",
    "    \n",
    "    return ids, texts, labels\n",
    "\n",
    "# File paths (update these paths as needed)\n",
    "train_responses_file = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-train.jsonl'\n",
    "train_labels_file = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-train-labels.jsonl'\n",
    "val_responses_file   = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-validation.jsonl'\n",
    "val_labels_file      = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-validation-labels.jsonl'\n",
    "test_responses_file  = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-test.jsonl'\n",
    "test_labels_file     = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-test-labels.jsonl'\n",
    "\n",
    "# Load train and validation datasets separately\n",
    "train_ids, train_texts, train_labels = load_dataset(train_responses_file, train_labels_file)\n",
    "val_ids, val_texts, val_labels = load_dataset(val_responses_file, val_labels_file)\n",
    "\n",
    "# Combine train and validation sets into one training set\n",
    "combined_ids = train_ids + val_ids\n",
    "combined_texts = train_texts + val_texts\n",
    "combined_labels = train_labels + val_labels\n",
    "\n",
    "# Load test dataset\n",
    "test_ids, test_texts, test_labels = load_dataset(test_responses_file, test_labels_file)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Experiment: Logistic Regression with TF-IDF for Advertisement Detection\n",
    "# Classifier: Logistic Regression (predicts label 1 as advertisement)\n",
    "# Feature Extraction: TF-IDF\n",
    "# Goal: Evaluate performance specifically for detecting advertisements (label 1)\n",
    "# -----------------------------------------------------\n",
    "\n",
    "# Build the pipeline: TF-IDF vectorizer + Logistic Regression\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(stop_words='english', max_df=0.95),\n",
    "    LogisticRegression(class_weight='balanced',max_iter=1000, random_state=42)\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Cross-Validation on Combined Training Set\n",
    "# -------------------------\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# Use scoring 'f1' which, for binary classification, computes the F1 score for the positive class (label 1)\n",
    "cv_scores = cross_val_score(pipeline, combined_texts, combined_labels, cv=cv, scoring='f1')\n",
    "print(\"Cross-validation F1 Score (for ad detection, label=1) on Combined Training Set:\", cv_scores)\n",
    "print(\"Mean Cross-validation F1 Score:\", np.mean(cv_scores))\n",
    "\n",
    "# -------------------------\n",
    "# Train the Model on the Full Combined Training Set\n",
    "# -------------------------\n",
    "pipeline.fit(combined_texts, combined_labels)\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation on Combined Training Set\n",
    "# -------------------------\n",
    "train_preds = pipeline.predict(combined_texts)\n",
    "train_report_dict = classification_report(combined_labels, train_preds, output_dict=True)\n",
    "train_cm = confusion_matrix(combined_labels, train_preds)\n",
    "# Save training evaluation to CSV\n",
    "df_train_report = pd.DataFrame(train_report_dict).transpose()\n",
    "df_train_report.to_csv('/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/Advertisment-Detection/csv-results/baseline/train_classification_report.csv', index=True)\n",
    "\n",
    "df_train_cm = pd.DataFrame(train_cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "df_train_cm.to_csv('/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/Advertisment-Detection/csv-results/baseline/train_confusion_matrix.csv', index=True)\n",
    "\n",
    "print(\"\\nCombined Training Set Evaluation:\")\n",
    "print(classification_report(combined_labels, train_preds))\n",
    "print(\"Confusion Matrix (Combined Training):\")\n",
    "print(confusion_matrix(combined_labels, train_preds))\n",
    "# Calculate F1 Score for label 1 explicitly:\n",
    "print(\"F1 Score for ads (label 1):\", f1_score(combined_labels, train_preds, pos_label=1))\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation on Test Set\n",
    "# -------------------------\n",
    "test_preds = pipeline.predict(test_texts)\n",
    "test_report_dict = classification_report(test_labels, test_preds, output_dict=True)\n",
    "test_cm = confusion_matrix(test_labels, test_preds)\n",
    "\n",
    "# Save test evaluation to CSV\n",
    "df_test_report = pd.DataFrame(test_report_dict).transpose()\n",
    "df_test_report.to_csv('/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/Advertisment-Detection/csv-results/baseline/test_classification_report.csv', index=True)\n",
    "\n",
    "df_test_cm = pd.DataFrame(test_cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "df_test_cm.to_csv('/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/Advertisment-Detection/csv-results/baseline/test_confusion_matrix.csv', index=True)\n",
    "\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(classification_report(test_labels, test_preds))\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "print(\"Confusion Matrix (Test):\")\n",
    "print(cm)\n",
    "print(\"F1 Score for ads (label 1):\", f1_score(test_labels, test_preds, pos_label=1))\n",
    "\n",
    "# Calculate additional metrics for label 1 based on the confusion matrix\n",
    "TN, FP, FN, TP = cm[0,0], cm[0,1], cm[1,0], cm[1,1]\n",
    "detection_accuracy = TP / (TP + FN) if (TP + FN) > 0 else 0  # Recall for ads\n",
    "false_negative_rate = FN / (TP + FN) if (TP + FN) > 0 else 0\n",
    "false_positive_rate = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "\n",
    "print(\"Detection Accuracy for ads (label 1):\", detection_accuracy)\n",
    "print(\"False Negative Rate for ads (label 1):\", false_negative_rate)\n",
    "print(\"False Positive Rate for ads (label 1):\", false_positive_rate)\n",
    "\n",
    "# Additional snippet to calculate and print the F1 score for detecting ads (label 1)\n",
    "# Here, y_true is test_labels and y_pred is test_preds\n",
    "f1_ads = f1_score(test_labels, test_preds, pos_label=1)\n",
    "print(\"F1-score for detecting ads:\", f1_ads)\n",
    "\n",
    "# Calculate additional metrics for label 0 (non-ads) by treating label 0 as the positive class\n",
    "# For label 0:\n",
    "#   True Positives (TP_0) = TN (non-ads correctly predicted as non-ads)\n",
    "#   False Negatives (FN_0) = FP (non-ads predicted as ads)\n",
    "#   False Positives (FP_0) = FN (ads predicted as non-ads)\n",
    "#   True Negatives (TN_0) = TP (ads correctly predicted as ads)\n",
    "detection_accuracy_non_ads = TN / (TN + FP) if (TN + FP) > 0 else 0  # Recall for non-ads\n",
    "false_negative_rate_non_ads = FP / (TN + FP) if (TN + FP) > 0 else 0\n",
    "false_positive_rate_non_ads = FN / (FN + TP) if (FN + TP) > 0 else 0\n",
    "\n",
    "print(\"Detection Accuracy for non-ads (label 0):\", detection_accuracy_non_ads)\n",
    "print(\"False Negative Rate for non-ads (label 0):\", false_negative_rate_non_ads)\n",
    "print(\"False Positive Rate for non-ads (label 0):\", false_positive_rate_non_ads)\n",
    "# Additional snippet to calculate and print the F1 score for detecting ads (label 0)\n",
    "# Here, y_true is test_labels and y_pred is test_preds\n",
    "f1_ads = f1_score(test_labels, test_preds, pos_label=0)\n",
    "print(\"F1-score for non-detecting ads:\", f1_ads)\n",
    "\n",
    "# -------------------------\n",
    "# Submission File Generation\n",
    "# -------------------------\n",
    "submission_file = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/Advertisment-Detection/Submission/baseline2.jsonl'\n",
    "with open(submission_file, 'w', encoding='utf-8') as f_out:\n",
    "    for instance_id, pred in zip(test_ids, test_preds):\n",
    "        result = {\n",
    "            \"id\": instance_id,\n",
    "            \"label\": int(pred),  # ensuring it's an integer (0 or 1)\n",
    "            \"tag\": \"myGroupMyMethod\"\n",
    "        }\n",
    "        f_out.write(json.dumps(result) + \"\\n\")\n",
    "        \n",
    "print(f\"\\nSubmission file saved to: {submission_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai==0.28) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai==0.28) (4.66.5)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai==0.28) (3.10.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.20->openai==0.28) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->openai==0.28) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->openai==0.28) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->openai==0.28) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->openai==0.28) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->openai==0.28) (1.15.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from yarl<2.0,>=1.12.0->aiohttp->openai==0.28) (0.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 1.72.0\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: Apache-2.0\n",
      "Location: /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages\n",
      "Requires: anyio, distro, httpx, jiter, pydantic, sniffio, tqdm, typing-extensions\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.28.0)\n",
      "Collecting openai\n",
      "  Downloading openai-1.72.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Downloading openai-1.72.0-py3-none-any.whl (643 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m643.9/643.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.28.0\n",
      "    Uninstalling openai-0.28.0:\n",
      "      Successfully uninstalled openai-0.28.0\n",
      "Successfully installed openai-1.72.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user sent a test request asking for a short poem. They might be checking if the system works or just experimenting.\n",
      "\n",
      "I should keep it simple and elegant since they didn't specify a theme.\n",
      "\n",
      "A nature-themed poem would be safe and universally appealing.\n",
      "\n",
      "Let me craft something with imagery like stars, night, etc., to make it vivid.\n",
      "</think>\n",
      "\n",
      "Here's a short poem for you:\n",
      "\n",
      "Stars whisper in the midnight sky,  \n",
      "Silent waves caress the shore.  \n",
      "In this moment, time stands still,  \n",
      "And peace is yours once more.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-zrc8cPMFxVaiB2u5QZbXdA\",\n",
    "    base_url=\"https://llms-inference.innkube.fim.uni-passau.de/v1\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseekr1\",  # 👈 must be a supported model\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"this is a test request, write a short poem\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
