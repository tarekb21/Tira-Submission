{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfbadd8b",
   "metadata": {},
   "source": [
    "# Full RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "271d1055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /opt/conda/lib/python3.12/site-packages (1.11.0)\n",
      "Requirement already satisfied: sentence-transformers in /opt/conda/lib/python3.12/site-packages (4.1.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.12/site-packages (4.51.3)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.12/site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /opt/conda/lib/python3.12/site-packages (from faiss-cpu) (2.2.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from faiss-cpu) (23.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (0.31.2)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (69.5.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu sentence-transformers transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad45b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/conda/lib/python3.12/site-packages (1.78.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.12/site-packages (from openai) (2.11.4)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.12/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/conda/lib/python3.12/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d248c0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "072e24a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.12/site-packages (3.8.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.12/site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.12/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.12/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /opt/conda/lib/python3.12/site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.12/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.12/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.12/site-packages (from spacy) (0.15.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.12/site-packages (from spacy) (4.66.4)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.12/site-packages (from spacy) (2.2.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from spacy) (2.32.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.12/site-packages (from spacy) (2.11.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from spacy) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.12/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/conda/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/conda/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /opt/conda/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click<8.2,>=8.0.0 in /opt/conda/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9770070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hf_xet in /opt/conda/lib/python3.12/site-packages (1.1.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hf_xet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227f781c",
   "metadata": {},
   "source": [
    "## Advertisement Classification Pipeline\n",
    "\n",
    "1. **Helpers**  \n",
    "   Define `load_jsonl` and `load_and_label` to read JSONL files and merge examples with their labels.\n",
    "\n",
    "2. **Load & Merge Train + Validation Data**  \n",
    "   - Load `responses-train.jsonl` & `responses-train-labels.jsonl`  \n",
    "   - Load `responses-validation.jsonl` & `responses-validation-labels.jsonl`  \n",
    "   - Combine both into a single `train_data` pool.\n",
    "\n",
    "3. **Index by Topic & Label**  \n",
    "   Organize `train_data` into `docs_by_topic_label[meta_topic][label]` for per-topic, per-label grouping.\n",
    "\n",
    "4. **Embed All Responses**  \n",
    "   Use `SentenceTransformer(EMBED_MODEL)` to compute L2-normalized vector embeddings for every response.\n",
    "\n",
    "5. **Build & Save FAISS Indices**  \n",
    "   For each topic and label:  \n",
    "   - Create a flat inner-product index (`IndexFlatIP`)  \n",
    "   - Add all embeddings  \n",
    "   - Serialize `(faiss_indices, plain_docs)` to `faiss_indices2.pkl`.\n",
    "\n",
    "6. **Load FAISS Indices**  \n",
    "   Load back the pickle to restore `faiss_indices` and document lookups for inference.\n",
    "\n",
    "7. **Query Embedding Function**  \n",
    "   Define `embed_query(text)` to produce a normalized embedding for any new response.\n",
    "\n",
    "8. **Retrieve Top-K per Label**  \n",
    "   - **If topic exists:** search that topic’s indices for top `K_PER_LABEL` neighbors in each label  \n",
    "   - **Else fallback:** pool all docs globally and pick top K per label by inner product.\n",
    "\n",
    "9. **Rerank with Cross-Encoder**  \n",
    "   Score the retrieved candidates with `CrossEncoder(RERANKER_MODEL)` and select the top `FINAL_TOP_M`, enforcing up to two examples per label.\n",
    "\n",
    "10. **Prompt Construction & Classification**  \n",
    "    Build a zero-shot prompt injecting the reranked examples, call the LLM (`MODEL_NAME`) with `temperature=0.0`, and output a binary label (0 or 1).\n",
    "\n",
    "11. **Evaluation on Test Set**  \n",
    "    - Load test responses & labels  \n",
    "    - Classify each example through the full pipeline  \n",
    "    - Compute and print the confusion matrix and detailed classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55d6d8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import faiss\n",
    "import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tqdm import tqdm\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96dfece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── CONFIG ─────────────────────────────────────────────────────────────────────\n",
    "API_KEY    = os.getenv(\"OPENAI_API_KEY\", \"sk-8TwcodIENxaHJBtD7-bF7A\")\n",
    "BASE_URL   = \"https://llms-inference.innkube.fim.uni-passau.de\"\n",
    "MODEL_NAME = \"llama3.1\"\n",
    "\n",
    "EMBED_MODEL    = \"all-MiniLM-L6-v2\"\n",
    "RERANKER_MODEL = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "\n",
    "K_PER_LABEL     = 5   # retrieve per label\n",
    "FINAL_TOP_M     = 4   # rerank down to 4 total\n",
    "DIST_THRESHOLD  = 0.0 # not used for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61e96dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── STEP 0: Helpers ─────────────────────────────────────────────────────────────\n",
    "def load_jsonl(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return [json.loads(line) for line in f]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb939bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 16/16 [00:00<00:00, 18.83it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:00<00:00, 36.16it/s]\n",
      "Batches: 100%|██████████| 18/18 [00:00<00:00, 32.88it/s]\n",
      "Batches: 100%|██████████| 38/38 [00:01<00:00, 34.97it/s]\n",
      "Batches: 100%|██████████| 22/22 [00:00<00:00, 33.90it/s]\n",
      "Batches: 100%|██████████| 39/39 [00:01<00:00, 36.82it/s]\n",
      "Batches: 100%|██████████| 13/13 [00:00<00:00, 34.15it/s]\n",
      "Batches: 100%|██████████| 27/27 [00:00<00:00, 33.98it/s]\n",
      "Batches: 100%|██████████| 17/17 [00:00<00:00, 34.02it/s]\n",
      "Batches: 100%|██████████| 29/29 [00:00<00:00, 35.04it/s]\n",
      "Batches: 100%|██████████| 15/15 [00:00<00:00, 34.31it/s]\n",
      "Batches: 100%|██████████| 30/30 [00:00<00:00, 37.72it/s]\n",
      "Batches: 100%|██████████| 21/21 [00:00<00:00, 36.41it/s]\n",
      "Batches: 100%|██████████| 39/39 [00:01<00:00, 35.77it/s]\n",
      "Batches: 100%|██████████| 19/19 [00:00<00:00, 35.22it/s]\n",
      "Batches: 100%|██████████| 35/35 [00:00<00:00, 36.72it/s]\n",
      "Batches: 100%|██████████| 13/13 [00:00<00:00, 32.43it/s]\n",
      "Batches: 100%|██████████| 22/22 [00:00<00:00, 34.76it/s]\n",
      "Batches: 100%|██████████| 11/11 [00:00<00:00, 33.94it/s]\n",
      "Batches: 100%|██████████| 15/15 [00:00<00:00, 31.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# ─── STEP 1: LOAD & MERGE TRAIN + VALIDATION DATA ─────────────────────────────\n",
    "def load_and_label(jsonl_path, labels_path):\n",
    "    examples = load_jsonl(jsonl_path)\n",
    "    labels   = load_jsonl(labels_path)\n",
    "    lbl_map  = {l['id']: l['label'] for l in labels}\n",
    "    merged   = []\n",
    "    for r in examples:\n",
    "        if r['id'] in lbl_map:\n",
    "            merged.append({\n",
    "                'id':         r['id'],\n",
    "                'meta_topic': r['meta_topic'],\n",
    "                'response':   r['response'],\n",
    "                'label':      lbl_map[r['id']]\n",
    "            })\n",
    "    return merged\n",
    "\n",
    "# load train\n",
    "train_data = load_and_label(\n",
    "    \"Dataset/responses-train.jsonl\",\n",
    "    \"Dataset/responses-train-labels.jsonl\"\n",
    ")\n",
    "\n",
    "# load validation\n",
    "valid_data = load_and_label(\n",
    "    \"Dataset/responses-validation.jsonl\",\n",
    "    \"Dataset/responses-validation-labels.jsonl\"\n",
    ")\n",
    "\n",
    "# merge them into one big “train” pool\n",
    "train_data.extend(valid_data)\n",
    "\n",
    "# ─── STEP 2: INDEX BY TOPIC & LABEL ─────────────────────────────────────────────\n",
    "docs_by_topic_label = defaultdict(lambda: defaultdict(list))\n",
    "for doc in train_data:\n",
    "    docs_by_topic_label[doc['meta_topic']][doc['label']].append(doc)\n",
    "\n",
    "# ─── STEP 3: EMBED ALL RESPONSES ────────────────────────────────────────────────\n",
    "embedder = SentenceTransformer(EMBED_MODEL)\n",
    "for topic, labels in docs_by_topic_label.items():\n",
    "    for label, docs in labels.items():\n",
    "        texts = [d['response'] for d in docs]\n",
    "        embs  = embedder.encode(texts, show_progress_bar=True, normalize_embeddings=True)\n",
    "        for doc, emb in zip(docs, embs):\n",
    "            doc['embedding'] = emb\n",
    "\n",
    "# ─── STEP 4: BUILD & SAVE FAISS INDEX (fixed) ───────────────────────────────────\n",
    "faiss_indices = {}\n",
    "for topic, labels in docs_by_topic_label.items():\n",
    "    faiss_indices[topic] = {}\n",
    "    for label, docs in labels.items():\n",
    "        dim   = docs[0]['embedding'].shape[0]\n",
    "        index = faiss.IndexFlatIP(dim)\n",
    "        array = np.stack([d['embedding'] for d in docs])\n",
    "        index.add(array)\n",
    "        faiss_indices[topic][label] = index\n",
    "\n",
    "# Convert docs_by_topic_label (a defaultdict) into a nested plain dict\n",
    "plain_docs = {\n",
    "    topic: { label: docs for label, docs in label_dict.items() }\n",
    "    for topic, label_dict in docs_by_topic_label.items()\n",
    "}\n",
    "\n",
    "with open(\"RAG FAISS/faiss_indices2.pkl\", \"wb\") as f:\n",
    "    # Now both objects are picklable!\n",
    "    pickle.dump((faiss_indices, plain_docs), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe0b1393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── STEP 5: LOAD FAISS INDEX (fixed) ───────────────────────────────────────────\n",
    "with open(\"RAG FAISS/faiss_indices2.pkl\", \"rb\") as f:\n",
    "    faiss_indices, plain_docs = pickle.load(f)\n",
    "\n",
    "# If you still want a defaultdict structure:\n",
    "docs_by_topic_label = defaultdict(lambda: defaultdict(list))\n",
    "for topic, label_dict in plain_docs.items():\n",
    "    for label, docs in label_dict.items():\n",
    "        docs_by_topic_label[topic][label] = docs\n",
    "\n",
    "\n",
    "# ─── STEP 6: QUERY EMBEDDING FUNCTION ───────────────────────────────────────────\n",
    "def embed_query(text):\n",
    "    emb = embedder.encode([text], normalize_embeddings=True)\n",
    "    return emb\n",
    "\n",
    "# ─── STEP 7: RETRIEVE TOP-K PER LABEL ───────────────────────────────────────────\n",
    "def retrieve_by_label(query_emb, topic, k=K_PER_LABEL):\n",
    "    # ─── Case 1: topic exists ────────────────────────\n",
    "    if topic in faiss_indices:\n",
    "        pool = {}\n",
    "        for label in (0, 1):\n",
    "            idx = faiss_indices[topic].get(label)\n",
    "            if idx is None: \n",
    "                continue\n",
    "            D, I = idx.search(query_emb, k)\n",
    "            docs = docs_by_topic_label[topic].get(label, [])\n",
    "            pool[label] = [docs[i] for i in I[0] if i != -1]\n",
    "        return pool\n",
    "\n",
    "    # ─── Case 2: topic missing — global fallback ─────\n",
    "    # Flatten all docs across all topics\n",
    "    all_docs = []\n",
    "    for t, label_dict in docs_by_topic_label.items():\n",
    "        for docs in label_dict.values():\n",
    "            all_docs.extend(docs)\n",
    "\n",
    "    # Stack embeddings and compute cosine similarities\n",
    "    emb_matrix = np.stack([d['embedding'] for d in all_docs])  # shape: [N, dim]\n",
    "    # since embeddings were normalized, inner product == cosine\n",
    "    sims = (emb_matrix @ query_emb.T).squeeze()                # shape: [N]\n",
    "\n",
    "    # Sort descending and pick top k per label\n",
    "    sorted_idxs = np.argsort(sims)[::-1]\n",
    "    pool = {0: [], 1: []}\n",
    "    for idx in sorted_idxs:\n",
    "        doc = all_docs[idx]\n",
    "        lab = doc['label']\n",
    "        if len(pool[lab]) < k:\n",
    "            pool[lab].append(doc)\n",
    "        # stop once both labels have k each\n",
    "        if len(pool[0]) >= k and len(pool[1]) >= k:\n",
    "            break\n",
    "\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf2e7779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── STEP 8: RERANK WITH CROSSENCODER ──────────────────────────────────────────\n",
    "#Modified to always have the same number of advertisements and no-advertisements examples to limit the bias.\n",
    "reranker = CrossEncoder(RERANKER_MODEL)\n",
    "\n",
    "def rerank_pool(response, pool, top_m=FINAL_TOP_M):\n",
    "    #print(pool)\n",
    "    candidates_no_ad = pool[0]\n",
    "    #print(candidates_no_ad)\n",
    "    pairs_no_ad      = [(response, d['response']) for d in candidates_no_ad]\n",
    "    scores_no_ad     = reranker.predict(pairs_no_ad)\n",
    "    idxs_no_ad       = np.argsort(scores_no_ad)[-top_m:][::-1]\n",
    "    selected_no_ad   = [candidates_no_ad[i] for i in idxs_no_ad]\n",
    "\n",
    "    candidates_ad = pool[1]\n",
    "    pairs_ad      = [(response, d['response']) for d in candidates_ad]\n",
    "    scores_ad     = reranker.predict(pairs_ad)\n",
    "    idxs_ad       = np.argsort(scores_ad)[-top_m:][::-1]\n",
    "    selected_ad   = [candidates_ad[i] for i in idxs_ad]\n",
    "    # enforce 2 per label if possible\n",
    "    out =  list(chain.from_iterable(zip(selected_ad[:top_m//2],selected_no_ad[:top_m//2])))\n",
    "    #for d in selected_ad:\n",
    "    #    if len(out[d['label']]) < 2:\n",
    "    #        out[d['label']].append(d)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9940614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── NEW STEP 9: PROMPT & CLASSIFY ─────────────────────────────────────────────────\n",
    "# Modified with some prompt engineering and use of a stronger model.\n",
    "client = OpenAI()\n",
    "\n",
    "def make_prompt(response, context):\n",
    "    p = \"Examples:\\n\"\n",
    "    for c in context:\n",
    "        label_example = \"AD\" if c['label']==1 else \"NO_AD\"\n",
    "        p += f\"{{text: \\\"{c['response']}\\\", label: {label_example}}}\\n\"\n",
    "    p += f\"\\nResponse:\\n\\\"{response}\\\"\\nLabel (NO_AD or AD):\"\n",
    "    return p\n",
    "\n",
    "def classify(response, topic):\n",
    "    system_prompt = \"You are a helpful assistant. Your goal is to classify the last text you received as an advertisement or not.\\nAn advertisement promotes a product, service, or event whereas non-advertisements only state objective information about the product, service, or event. Be sure to correctly capture the nuances between advertisements and informative texts.\\nYou will be provided examples. Using your knowledge and these examples if they are relevant, output ONLY AD if the last Response is an advertisement or output NO_AD if it is not an advertisement.\"\n",
    "    q_emb = embed_query(response)\n",
    "    pool  = retrieve_by_label(q_emb, topic)\n",
    "    if not any(pool.values()):\n",
    "        return 0, []\n",
    "    ctx   = rerank_pool(response, pool)\n",
    "    prompt = make_prompt(response, ctx)\n",
    "    #print(prompt)\n",
    "    resp   = client.chat.completions.create(\n",
    "        model       = \"gpt-4o\",\n",
    "        messages    = [{\"role\":\"system\", \"content\": system_prompt},{\"role\":\"user\",\"content\":prompt}],\n",
    "        temperature = 0.0,\n",
    "        max_tokens  = 2\n",
    "    )\n",
    "    out = resp.choices[0].message.content.strip()\n",
    "    return (1 if out.startswith(\"AD\") else 0), ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e3eea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── llama3.1 NEW STEP 9: PROMPT & CLASSIFY ─────────────────────────────────────────────────\n",
    "# Modified with some prompt engineering and use of a stronger model.\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL, \n",
    ")\n",
    "\n",
    "def make_prompt(response, context):\n",
    "    p = \"Examples:\\n\"\n",
    "    for c in context:\n",
    "        label_example = \"AD\" if c['label']==1 else \"NO_AD\"\n",
    "        p += f\"{{text: \\\"{c['response']}\\\", label: {label_example}}}\\n\"\n",
    "    p += f\"\\nResponse:\\n\\\"{response}\\\"\\nLabel (NO_AD or AD):\"\n",
    "    return p\n",
    "\n",
    "def classify(response, topic):\n",
    "    system_prompt = \"You are a helpful assistant. Your goal is to classify the last text you received as an advertisement or not.\\nAn advertisement promotes a product, service, or event whereas non-advertisements only state objective information about the product, service, or event. Be sure to correctly capture the nuances between advertisements and informative texts.\\nYou will be provided examples. Using your knowledge and these examples if they are relevant, output ONLY AD if the last Response is an advertisement or output NO_AD if it is not an advertisement.\"\n",
    "    q_emb = embed_query(response)\n",
    "    pool  = retrieve_by_label(q_emb, topic)\n",
    "    if not any(pool.values()):\n",
    "        return 0, []\n",
    "    ctx   = rerank_pool(response, pool)\n",
    "    prompt = make_prompt(response, ctx)\n",
    "    #print(prompt)\n",
    "    resp   = client.chat.completions.create(\n",
    "        model       = MODEL_NAME,\n",
    "        messages    = [{\"role\":\"system\", \"content\": system_prompt},{\"role\":\"user\",\"content\":prompt}],\n",
    "        temperature = 0.0,\n",
    "        max_tokens  = 2\n",
    "    )\n",
    "    out = resp.choices[0].message.content.strip()\n",
    "    return (1 if out.startswith(\"AD\") else 0), ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "332e4158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation of the classifier: 100%|██████████| 2600/2600 [1:44:40<00:00,  2.42s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[785 902]\n",
      " [ 81 832]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.906     0.465     0.615      1687\n",
      "           1      0.480     0.911     0.629       913\n",
      "\n",
      "    accuracy                          0.622      2600\n",
      "   macro avg      0.693     0.688     0.622      2600\n",
      "weighted avg      0.757     0.622     0.620      2600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ─── llama3.1 STEP 10: EVALUATE ON TEST SET ─────────────────────────────────────────────\n",
    "# 10.1 load & merge test\n",
    "test_resp = load_jsonl(\"/root/Ad-Detection/Expirements/RAG 3/Dataset/responses-test.jsonl\")\n",
    "test_lbl  = load_jsonl(\"/root/Ad-Detection/Expirements/RAG 3/Dataset/responses-test-labels.jsonl\")\n",
    "test_map  = {l['id']: l['label'] for l in test_lbl}\n",
    "\n",
    "test_data = []\n",
    "for r in test_resp:\n",
    "    if r['id'] in test_map:\n",
    "        test_data.append({\n",
    "            'id':         r['id'],\n",
    "            'meta_topic': r['meta_topic'],\n",
    "            'response':   r['response'],\n",
    "            'label':      test_map[r['id']]\n",
    "        })\n",
    "\n",
    "# 10.2 classify and collect\n",
    "y_true, y_pred = [], []\n",
    "for i in tqdm(range(len(test_data)), desc=\"Evaluation of the classifier\"):\n",
    "    ex=test_data[i]\n",
    "    pred, _ = classify(ex['response'], ex['meta_topic'])\n",
    "    y_true.append(ex['label'])\n",
    "    y_pred.append(pred)\n",
    "\n",
    "# 10.3 metrics\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
